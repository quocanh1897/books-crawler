# crawler-descryptor

Decrypt chapter content from the metruyencv mobile API without needing the Android emulator.

## Status: SOLVED

The encryption has been fully reverse-engineered. No external key, Frida hooks, or emulator is needed — the AES key is embedded in every API response and extracted automatically.

Validated: decrypted output matches the production crawler's database plaintext character-for-character.

---

## Decryption Algorithm

### Overview

The mobile API (`android.lonoapp.net/api/chapters/{id}`) returns a `content` field that is a **modified base64 string**. The server injects 16 characters of key material into the base64 at a fixed position. The app extracts these characters, removes them to recover clean base64, then decrypts the payload.

**Cipher**: AES-128-CBC with PKCS7 padding, wrapped in a Laravel encryption envelope.

### Step-by-step

Given the raw `content` string from the API response:

```
eyJpdiI6IkVlN21ta2UFvSV5Q5aej6kVRk94RFUyWm5MMWFjQW91OFE9PSIsInZhbH...
^                ^               ^
0               17              33
```

#### Step 1 — Extract the AES key

Characters at positions **[17:33]** (16 chars) are the AES-128 encryption key:

```python
key_chars = content[17:33]          # e.g. "2UFvSV5Q5aej6kVR"
key_bytes = bytes(ord(c) for c in key_chars)  # 16 bytes
```

These are ASCII printable characters. Their byte values (code units) are used directly as the 16-byte AES key. A new random key is generated by the server for every response.

#### Step 2 — Remove key chars to recover clean base64

```python
clean_b64 = content.replace(key_chars, "", 1)
```

The first occurrence of those 16 characters is removed. What remains is a valid base64 string.

#### Step 3 — Decode the Laravel encryption envelope

```python
raw_bytes = base64.b64decode(clean_b64)
envelope_str = raw_bytes.decode("utf-8")
envelope = json.loads(envelope_str)
# envelope = {"iv": "<base64>", "value": "<base64>", "mac": "<hex>"}
```

The clean base64 decodes to a UTF-8 JSON string containing three fields:

| Field   | Format        | Description                           |
| ------- | ------------- | ------------------------------------- |
| `iv`    | base64 string | 16-byte AES initialization vector     |
| `value` | base64 string | AES-128-CBC ciphertext (PKCS7 padded) |
| `mac`   | 64-char hex   | HMAC-SHA256 integrity digest          |

#### Step 4 — Decode the IV and ciphertext

```python
iv = base64.b64decode(envelope["iv"])           # 16 bytes
ciphertext = base64.b64decode(envelope["value"]) # N * 16 bytes
```

The IV in the clean envelope is a standard base64 string — no obfuscation. (The "corrupted IV" observed in earlier analysis was caused by decoding the content _without_ removing the injected key chars first.)

#### Step 5 — Decrypt with AES-128-CBC

```python
from Crypto.Cipher import AES
from Crypto.Util.Padding import unpad

cipher = AES.new(key_bytes, AES.MODE_CBC, iv)
plaintext = unpad(cipher.decrypt(ciphertext), AES.block_size)
text = plaintext.decode("utf-8").strip()
```

The result is the chapter's plain text content in Vietnamese.

### Visual diagram

```
API Response content field:
┌─────────────────┬────────────────┬──────────────────────────────────────────┐
│  base64 prefix  │  16-char KEY   │  base64 continuation                     │
│  content[0:17]  │ content[17:33] │  content[33:]                            │
└─────────────────┴────────────────┴──────────────────────────────────────────┘
                  ↓ extract        ↓ remove key, rejoin
            AES-128 key      clean base64 string
                                   ↓ base64 decode + UTF-8 + JSON parse
                             ┌─────────────────────────────────┐
                             │ { "iv": "...",                  │
                             │   "value": "...",               │
                             │   "mac": "..." }                │
                             └─────────────────────────────────┘
                                   ↓ base64 decode iv & value
                             AES-128-CBC decrypt(key, iv, value)
                                   ↓ PKCS7 unpad + UTF-8
                             "Chương 1: Tiêu Phàm trọng sinh..."
```

### Key properties

- **Key per response**: The server generates a new random 16-byte key for every API call. Even requesting the same chapter twice yields different keys and ciphertexts.
- **Key transport**: The key is embedded directly in the content string, making the encryption an obfuscation scheme rather than true secret-key cryptography.
- **No external key needed**: Unlike a typical AES setup, there is no shared secret — the key travels with the ciphertext.

---

## How It Was Discovered

The algorithm was reverse-engineered through **static analysis** of the Flutter/Dart AOT binary:

1. **blutter** (Dart AOT decompiler) was run on `libapp.so` + `libflutter.so` from the APK
2. The decompiled assembly of `_getChapterDetailsEncrypt` in `novelfever/utils/api_client.dart` revealed:
   - `content.substring(17, 33)` — extract 16 characters at positions 17-32
   - `content.replaceAll(substring, "")` — remove them from the content
   - `base64.decode → utf8.decode → jsonDecode` — parse the clean envelope
   - `Uint8List.fromList(substring.codeUnits)` — convert chars to key bytes
   - `aesSetKeys(keyBytes, base64.decode(envelope["iv"]))` — set AES-128 key + IV
   - `aesDecrypt(base64.decode(envelope["value"]))` — decrypt the ciphertext
3. The `aes_crypt_null_safe` Dart package was identified as the crypto library
4. ARM64 instruction `mov x16, #0x42` (66) was identified as a **Smi-encoded** value (66 >> 1 = 33), resolving the `substring(17, 33)` end index

Previous approaches (Frida runtime hooking, exhaustive binary scanning, memory dumps) were unsuccessful because the key is not static — it changes with every API response.

---

## Setup

```bash
cd crawler-descryptor
pip install -r requirements.txt
```

## Usage

### Decrypt a single chapter

```bash
python3 main.py fetch-chapter 10340503
```

### Fetch all chapters of a book

```bash
python3 main.py fetch-book 100358
```

### Batch download specific books

```bash
python3 batch_download.py                     # download preset list
python3 batch_download.py 100441 101481 101486  # specific book IDs
python3 batch_download.py -w 15 --clean       # 15 workers, clean wrong data first
```

### Download from plan file

```bash
python3 download_top1000.py                   # download all books in ranking_books.json
python3 download_top1000.py -w 100            # 100 parallel workers
python3 download_top1000.py --plan custom.json  # custom book list (flat JSON array)
python3 download_top1000.py --exclude 100441 101481  # skip specific IDs
```

### Fetch full platform catalog

```bash
python3 fetch_catalog.py                # fetch all 30,486 books, audit vs local DB
python3 fetch_catalog.py --verify 926   # verify author ID 926 has expected books
python3 fetch_catalog.py --skip-fetch   # reuse existing full_catalog.json, just re-audit
```

### Download the full catalog (all missing books)

```bash
python3 download_top1000.py -w 100 --plan new_books_download.json      # 27,623 new books
python3 download_top1000.py -w 100 --plan partial_books_download.json  # 360 partial books
```

### Analyze encryption details

```bash
python3 main.py analyze 10340503
```

### Output

Chapters are saved to `crawler/output/{book_id}/` in the same format as the existing crawler:

```
crawler/output/{book_id}/
├── 0001_chapter-slug.txt    # temporary — cleaned up after import
├── 0002_chapter-slug.txt
├── ...
└── metadata.json            # kept permanently
```

After downloading, run `binslib/scripts/import.ts --cleanup` to import chapters
into the SQLite database and remove the `.txt` files. The epub-converter and
binslib website will then read chapters from the database.

## Project Structure

```
crawler-descryptor/
├── README.md                     # This file
├── PLAN.md                       # Original investigation plan (historical)
├── requirements.txt
├── main.py                       # CLI: fetch-chapter, fetch-book, analyze
├── batch_download.py             # Parallel batch download (specific book IDs)
├── download_top1000.py           # Parallel download from ranking/plan JSON files
├── fetch_catalog.py              # Full platform catalog fetcher + audit
├── full_catalog.json             # Complete catalog: 30,486 books
├── new_books_download.json       # 27,623 books not yet downloaded
├── partial_books_download.json   # 360 partially downloaded books
├── ranking_books.json            # 2,620 books from ranking API sweep (subset)
├── top1000_download_plan.json    # Top 1000 download plan with status (historical)
├── src/
│   ├── decrypt.py                # AES-128-CBC decryption + key extraction
│   ├── client.py                 # API client (chapter fetching, book lookup)
│   └── utils.py                  # Output formatting, file helpers
├── frida/                        # Historical — Frida hooks (no longer needed)
│   ├── hook_boringssl.js
│   ├── hook_dart_decrypt.js
│   └── hook_api_init.js
└── tests/
    ├── test_blutter_decrypt.py   # Decryption validation test
    ├── test_validate_vs_crawler.py  # Compare output with crawler DB
    └── samples/
        └── verified_pair.json    # Known plaintext-ciphertext pair
```
